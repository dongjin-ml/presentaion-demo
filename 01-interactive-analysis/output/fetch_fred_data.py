"""
FRED Data Fetcher - Consumer Credit Delinquency Risk Analysis
=============================================================
ì‹ ìš©ìœ„ì›íšŒ ë¯¸íŒ…ìš© ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ë³´ê³ ì„œ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

ìˆ˜ì§‘ ë°ì´í„°:
- DRCCLACBS: ì†Œë¹„ì ëŒ€ì¶œ ì—°ì²´ìœ¨
- UNRATE: ì‹¤ì—…ë¥ 
- FEDFUNDS: ê¸°ì¤€ê¸ˆë¦¬
- TOTALSL: ì†Œë¹„ì ì‹ ìš© ì´ì•¡

ë¶„ì„ ëª©ì :
1. í˜„ì¬ ì†Œë¹„ì ëŒ€ì¶œ ì—°ì²´ìœ¨ì´ ì •ìƒ ë²”ìœ„ì¸ê°€?
2. ì‹¤ì—…ë¥ , ê¸ˆë¦¬ ë“± ì„ í–‰ì§€í‘œì— ê²½ê³  ì‹ í˜¸ê°€ ìˆëŠ”ê°€?
3. 2008ë…„, 2020ë…„ ìœ„ê¸° ì§ì „ ìˆ˜ì¤€ê³¼ ë¹„êµí•˜ë©´?
4. ë¹¨ê°„ë¶ˆ/ë…¸ë€ë¶ˆ/ì´ˆë¡ë¶ˆ ì¢…í•© í‰ê°€
"""

import os
import json
import requests
import pandas as pd
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
PROJECT_ROOT = Path(__file__).parent.parent
load_dotenv(PROJECT_ROOT / ".env")

FRED_API_KEY = os.getenv("FRED_API_KEY")
FRED_BASE_URL = "https://api.stlouisfed.org/fred/series/observations"
OUTPUT_DIR = PROJECT_ROOT / "data" / "fred"

# ìˆ˜ì§‘í•  FRED ì‹œë¦¬ì¦ˆ (ì»¬ëŸ¼ ì„¤ëª… í¬í•¨)
SERIES_CONFIG = {
    "DRCCLACBS": {
        "name": "Delinquency Rate on Consumer Loans, All Commercial Banks",
        "name_kr": "ì†Œë¹„ì ëŒ€ì¶œ ì—°ì²´ìœ¨",
        "unit": "Percent",
        "frequency": "Quarterly",
        "description": "ìƒì—…ì€í–‰ì˜ ì†Œë¹„ì ëŒ€ì¶œ ì—°ì²´ìœ¨ (90ì¼ ì´ìƒ ì—°ì²´ ë¹„ìœ¨). ë†’ì„ìˆ˜ë¡ ì†Œë¹„ì ì‹ ìš© ë¦¬ìŠ¤í¬ ì¦ê°€.",
        "risk_threshold": {
            "green": "< 3.0%",
            "yellow": "3.0% - 4.5%",
            "red": "> 4.5%"
        },
        "historical_crisis": {
            "2008_peak": "6.77% (2009-Q4)",
            "2020_peak": "2.53% (2020-Q2)"
        }
    },
    "UNRATE": {
        "name": "Unemployment Rate",
        "name_kr": "ì‹¤ì—…ë¥ ",
        "unit": "Percent",
        "frequency": "Monthly",
        "description": "ë¯¸êµ­ ì „ì²´ ì‹¤ì—…ë¥  (ê³„ì ˆ ì¡°ì •). ê²½ê¸°ì¹¨ì²´ ì„ í–‰ì§€í‘œë¡œ ë†’ì„ìˆ˜ë¡ ì†Œë¹„ì ì‹ ìš© ìƒí™˜ ëŠ¥ë ¥ ì €í•˜.",
        "risk_threshold": {
            "green": "< 5.0%",
            "yellow": "5.0% - 7.0%",
            "red": "> 7.0%"
        },
        "historical_crisis": {
            "2008_peak": "10.0% (2009-10)",
            "2020_peak": "14.7% (2020-04)"
        }
    },
    "FEDFUNDS": {
        "name": "Federal Funds Effective Rate",
        "name_kr": "ì—°ë°©ê¸°ê¸ˆ ê¸ˆë¦¬",
        "unit": "Percent",
        "frequency": "Monthly",
        "description": "ì—°ë°©ì¤€ë¹„ì œë„ ê¸°ì¤€ê¸ˆë¦¬ (ì‹¤íš¨ê¸ˆë¦¬). ê¸‰ê²©í•œ ì¸ìƒì€ ì°¨ì… ë¹„ìš© ì¦ê°€ë¡œ ì—°ì²´ ê°€ëŠ¥ì„± ìƒìŠ¹.",
        "risk_threshold": {
            "green": "< 3.0%",
            "yellow": "3.0% - 5.0%",
            "red": "> 5.0%"
        },
        "historical_crisis": {
            "2008_before": "5.25% (2007)",
            "2020_before": "1.58% (2020-03)"
        }
    },
    "TOTALSL": {
        "name": "Total Consumer Credit Outstanding",
        "name_kr": "ì†Œë¹„ì ì‹ ìš© ì´ì•¡",
        "unit": "Billions of Dollars",
        "frequency": "Monthly",
        "description": "ë¯¸êµ­ ì „ì²´ ì†Œë¹„ì ì‹ ìš© ì”ì•¡ (ê³„ì ˆ ì¡°ì •). ê¸‰ì¦ ì‹œ ê³¼ë„í•œ ë ˆë²„ë¦¬ì§€ ìš°ë ¤.",
        "risk_threshold": {
            "note": "ì ˆëŒ€ê°’ë³´ë‹¤ ì¦ê°€ìœ¨(YoY)ë¡œ í‰ê°€"
        },
        "historical_crisis": {
            "2008_level": "$2,573B (2008-09)",
            "2020_level": "$4,197B (2020-02)"
        }
    }
}


def fetch_series(series_id: str, start_date: str = "2000-01-01") -> pd.DataFrame:
    """FREDì—ì„œ ë‹¨ì¼ ì‹œë¦¬ì¦ˆ ë°ì´í„° ìˆ˜ì§‘"""
    params = {
        "series_id": series_id,
        "api_key": FRED_API_KEY,
        "file_type": "json",
        "observation_start": start_date,
        "observation_end": datetime.now().strftime("%Y-%m-%d")
    }

    config = SERIES_CONFIG[series_id]
    print(f"  Fetching {series_id}: {config['name_kr']}...")

    response = requests.get(FRED_BASE_URL, params=params)
    response.raise_for_status()

    data = response.json().get("observations", [])
    df = pd.DataFrame(data)
    df["date"] = pd.to_datetime(df["date"])
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    df = df[["date", "value"]].rename(columns={"value": series_id})
    df = df.dropna()

    print(f"     -> {len(df)} observations ({df['date'].min():%Y-%m} ~ {df['date'].max():%Y-%m})")
    return df


def main():
    print("=" * 70)
    print("FRED Data Fetcher - ì‹ ìš©ìœ„ì›íšŒ ë¯¸íŒ…ìš© ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ë³´ê³ ì„œ")
    print("=" * 70)

    if not FRED_API_KEY:
        print("âŒ Error: FRED_API_KEY not found in .env file")
        return

    # ë°ì´í„° ìˆ˜ì§‘
    print("\n[1/3] FRED ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    dataframes = {}
    for series_id in SERIES_CONFIG:
        try:
            dataframes[series_id] = fetch_series(series_id)
        except Exception as e:
            print(f"     âŒ Error fetching {series_id}: {e}")
            return

    # ë°ì´í„° ë³‘í•© (ì›”ë³„ ê¸°ì¤€, ë¶„ê¸° ë°ì´í„°ëŠ” forward fill)
    print("\n[2/3] ë°ì´í„° ë³‘í•© ì¤‘...")
    merged = dataframes["UNRATE"][["date"]].copy()
    for series_id, df in dataframes.items():
        merged = merged.merge(df, on="date", how="left")
    merged = merged.ffill()
    print(f"     -> ë³‘í•© ì™„ë£Œ: {len(merged)} rows, {len(merged.columns)-1} indicators")

    # ì €ì¥
    print("\n[3/3] ë°ì´í„° ì €ì¥ ì¤‘...")
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # í†µí•© CSV ì €ì¥
    csv_path = OUTPUT_DIR / "consumer_credit_risk_data.csv"
    merged.to_csv(csv_path, index=False)
    print(f"     âœ“ ë°ì´í„°: {csv_path}")

    # ìµœì‹  ê°’ ì¶”ì¶œ
    latest_row = merged.iloc[-1]
    latest_values = {
        series_id: {
            "value": float(latest_row[series_id]),
            "date": latest_row["date"].strftime("%Y-%m-%d"),
            "unit": SERIES_CONFIG[series_id]["unit"]
        }
        for series_id in SERIES_CONFIG.keys()
    }

    # ë©”íƒ€ë°ì´í„° JSON ì €ì¥
    metadata = {
        "purpose": "ì‹ ìš©ìœ„ì›íšŒ ë¯¸íŒ…ìš© ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ë³´ê³ ì„œ",
        "source": "Federal Reserve Economic Data (FRED)",
        "api_url": "https://fred.stlouisfed.org/",
        "fetch_date": datetime.now().isoformat(),
        "data_period": {
            "start": merged["date"].min().strftime("%Y-%m-%d"),
            "end": merged["date"].max().strftime("%Y-%m-%d"),
            "observations": len(merged)
        },
        "analysis_requirements": [
            "1. í˜„ì¬ ì†Œë¹„ì ëŒ€ì¶œ ì—°ì²´ìœ¨ì´ ì •ìƒ ë²”ìœ„ì¸ê°€?",
            "2. ì‹¤ì—…ë¥ , ê¸ˆë¦¬ ë“± ì„ í–‰ì§€í‘œì— ê²½ê³  ì‹ í˜¸ê°€ ìˆëŠ”ê°€?",
            "3. 2008ë…„, 2020ë…„ ìœ„ê¸° ì§ì „ ìˆ˜ì¤€ê³¼ ë¹„êµí•˜ë©´?",
            "4. ë¹¨ê°„ë¶ˆ/ë…¸ë€ë¶ˆ/ì´ˆë¡ë¶ˆ ì¢…í•© í‰ê°€"
        ],
        "series": SERIES_CONFIG,
        "latest_values": latest_values,
        "data_file": str(csv_path.name)
    }

    json_path = OUTPUT_DIR / "metadata.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    print(f"     âœ“ ë©”íƒ€ë°ì´í„°: {json_path}")

    # ìµœì‹  ê°’ ì¶œë ¥
    print("\n" + "=" * 70)
    print("ìµœì‹  ë°ì´í„° (Latest Values)")
    print("=" * 70)
    for series_id, config in SERIES_CONFIG.items():
        val_info = latest_values[series_id]
        print(f"  â€¢ {config['name_kr']}: {val_info['value']:.2f} {val_info['unit']} ({val_info['date']})")

    print("\n" + "=" * 70)
    print("âœ“ ì™„ë£Œ! ë°ì´í„°ê°€ ./data/fred/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("=" * 70)
    print(f"\nğŸ“Š ë°ì´í„° íŒŒì¼: {csv_path}")
    print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„°: {json_path}")


if __name__ == "__main__":
    main()
